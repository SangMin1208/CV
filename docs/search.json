[
  {
    "objectID": "posts/02.Review_on_deep_learning.html",
    "href": "posts/02.Review_on_deep_learning.html",
    "title": "2. Review on Deep Learning",
    "section": "",
    "text": "- Shallow learning\n\nonly has one layer\nfeature : vector\n\n- Deep learning\n\nhas more than one layer\nuse Gradient Descent\nover fitting problem\n\n\nimput image(224 x 224 x 3) : width x height x channel\n\n\n\n- Extract optimal representation via End-to-End learning\n\n머신러닝은 각각의 task마다 새로운 모델 design 필요\n딥러닝은 다른 task에서도 괜찮은 표현력\n\n- Non-linearity\n\nDeep learning can represent non-linear data\nMost computer vision applications invlove data which requires non-linear mappings\n\n- 내가 생각한 고전 ML과 비교한 장점\n\nEnd-to-End learning\n\n자동으로 feature를 추출해서 학습\n새로운 task에 쉽게 적응가능(transfer learning)\n\n고전 ML은 일정수준에서 성능 향상 x, 딥러닝은 데이터와 코델 크기 커질수록 계속 성능 향상"
  },
  {
    "objectID": "posts/02.Review_on_deep_learning.html#deep-vs.-machine-learning",
    "href": "posts/02.Review_on_deep_learning.html#deep-vs.-machine-learning",
    "title": "2. Review on Deep Learning",
    "section": "",
    "text": "- Shallow learning\n\nonly has one layer\nfeature : vector\n\n- Deep learning\n\nhas more than one layer\nuse Gradient Descent\nover fitting problem\n\n\nimput image(224 x 224 x 3) : width x height x channel\n\n\n\n- Extract optimal representation via End-to-End learning\n\n머신러닝은 각각의 task마다 새로운 모델 design 필요\n딥러닝은 다른 task에서도 괜찮은 표현력\n\n- Non-linearity\n\nDeep learning can represent non-linear data\nMost computer vision applications invlove data which requires non-linear mappings\n\n- 내가 생각한 고전 ML과 비교한 장점\n\nEnd-to-End learning\n\n자동으로 feature를 추출해서 학습\n새로운 task에 쉽게 적응가능(transfer learning)\n\n고전 ML은 일정수준에서 성능 향상 x, 딥러닝은 데이터와 코델 크기 커질수록 계속 성능 향상"
  },
  {
    "objectID": "posts/02.Review_on_deep_learning.html#cnnsconvolutional-neural-networks",
    "href": "posts/02.Review_on_deep_learning.html#cnnsconvolutional-neural-networks",
    "title": "2. Review on Deep Learning",
    "section": "2. CNNs(Convolutional Neural Networks)",
    "text": "2. CNNs(Convolutional Neural Networks)\n# RGB image \\(\\rightarrow\\) Any Differentiable Layers(learnability) \\(\\rightarrow\\) Semantic labels\n\nA. Differentiable layers and Gradient descent\n# \\(I\\) \\(\\rightarrow\\) layer \\(h\\) \\(\\rightarrow\\) \\(X\\)\n\\(\\rightarrow\\) Any Differentiable intermediate Layer \\(f\\) whose parameter is \\(\\theta\\)\n\\(\\rightarrow\\) \\(y\\) \\(\\rightarrow\\) layer \\(g\\)(loss function) \\(\\rightarrow\\) Loss \\(L\\)(distance btw ground truth & prediction)\n\nforward rule(순전파) : \\(y = f(h(I);\\theta)\\:\\:\\) for \\(\\:\\: g(f(h(I);\\theta))=L\\)\nbackward rule(역전파) : \\(\\frac{dL}{dI} = \\frac{dX}{dI} \\times \\frac{dy}{dX} \\times \\frac{dL}{dy}\\)\nparameter update rule : \\(\\theta^{new} =  \\theta - \\epsilon(\\text{learning rate})\\frac{dy}{d\\theta}\\times\\frac{dL}{dy}\\)\n\n\n\nB. CNN architecture\n\n- 2D Convolution\n\n\n\n하이퍼 파라미터 Stride =2로 지정하면 2칸씩 움직임\n\n\n\n입력이 3채널(RGB) 이면 filter도 3채널\n각 채널마다 다른 가중치\nex) 3x3 vlfxjdlaus (3,3,3) - 27개의 가중치 존재\nn개의 filter를 사용해 n개의 feature map 생성\n입력 h,w,3 \\(\\rightarrow\\) ?,?,n\n\n- Pooling\n\n\nMax pooling & Average pooling\n\n\n\nActivation layer\n\n\n\n최종 CNN shape 요약"
  },
  {
    "objectID": "posts/01.Overview_and_OpenCV.html",
    "href": "posts/01.Overview_and_OpenCV.html",
    "title": "1. Overview and Open CV",
    "section": "",
    "text": "Understand what is computer vision/deep learning algorithms\nUnderstand how to implement image/video processing algorithms in Python using OpenCV.\nUnderstand how to implement/train/test convolutional neural networks (CNNs) and Transformer in PyTorch.\n\n\n\n\n- What is computer vision?\n\n- What is deep learning?\n\nAlphaGo is using a deep learning when training their parameters\nImageNet challenge (2012년 AlexNet(8 layers) \\(\\rightarrow\\) 2015년 ResNet(152 layers)) getting deeper\n\n\n\n\n\n- Image classification for Cifar-10 dataset.\n\nAssuming that images are composed of one main object.\n\n\n- Object detection\n\nImage could be composed of multiple objects\nDetect object location + class imformation\n\n\n- Semantic segmentation\n\nDetect object’s pixel-level location + class information\n\n\n- Image generation\n\ndraw new images by changing atrributes of the original images\n\n\n- Pose estimation\n\nRecognize 2D/3D poses of the main objects(body, hand, face)\n\n\n- 3D hand mesh reconstruction\n\n21 Keypoints(4points for finger(20 joint) + wrist(손목)(1 joint))\n778 vertices\n\n\n- 3D human mesh reconstruction\n\nabout 7000 vertices"
  },
  {
    "objectID": "posts/01.Overview_and_OpenCV.html#course-overview",
    "href": "posts/01.Overview_and_OpenCV.html#course-overview",
    "title": "1. Overview and Open CV",
    "section": "",
    "text": "Understand what is computer vision/deep learning algorithms\nUnderstand how to implement image/video processing algorithms in Python using OpenCV.\nUnderstand how to implement/train/test convolutional neural networks (CNNs) and Transformer in PyTorch.\n\n\n\n\n- What is computer vision?\n\n- What is deep learning?\n\nAlphaGo is using a deep learning when training their parameters\nImageNet challenge (2012년 AlexNet(8 layers) \\(\\rightarrow\\) 2015년 ResNet(152 layers)) getting deeper\n\n\n\n\n\n- Image classification for Cifar-10 dataset.\n\nAssuming that images are composed of one main object.\n\n\n- Object detection\n\nImage could be composed of multiple objects\nDetect object location + class imformation\n\n\n- Semantic segmentation\n\nDetect object’s pixel-level location + class information\n\n\n- Image generation\n\ndraw new images by changing atrributes of the original images\n\n\n- Pose estimation\n\nRecognize 2D/3D poses of the main objects(body, hand, face)\n\n\n- 3D hand mesh reconstruction\n\n21 Keypoints(4points for finger(20 joint) + wrist(손목)(1 joint))\n778 vertices\n\n\n- 3D human mesh reconstruction\n\nabout 7000 vertices"
  },
  {
    "objectID": "posts/01.Overview_and_OpenCV.html#open-cv",
    "href": "posts/01.Overview_and_OpenCV.html#open-cv",
    "title": "1. Overview and Open CV",
    "section": "2. Open CV",
    "text": "2. Open CV\n\nA. Image read\n- Import\n\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\n\n- 컬러 이미지로 불러오기 IMREAD_UNCHANGED\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n\nimg.shape\n\n(454, 680, 3)\n\n\n- 흑백 이미지로 불러오기 IMREAD_GRAYSCALE\n\nimg2 = cv2.imread('./example.jpg', cv2.IMREAD_GRAYSCALE)\n\nplt.imshow(img2, cmap = 'gray')\n\n\n\n\n\n\n\n\n\nimg2.shape\n\n(454, 680)\n\n\n\n\nB.Image processing\n- 사각형 추가하기\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\ncv2.rectangle(img, (50, 50), (150, 150), (255, 0, 0))\ncv2.rectangle(img, (300, 300), (100, 100), (0, 255, 0), 10)\ncv2.rectangle(img, (450, 200), (200, 450), (0, 0, 255), -1)\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- polylines 그리기\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\npts1 = np.array([[50,50], [150,150], [100,140], [200,240]], dtype=np.int32)\ncv2.polylines(img, [pts1], False, (255,0,0))\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- 원 그리기\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\ncv2.circle(img, (150,150), 100, (255,0,0))\ncv2.ellipse(img, ((325,300), (150,100), 0), (0,255,0), 5)\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- Put texts\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\ncv2.putText(img, 'UNIST CSE48001 Computer Vision!', (20,50), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0))\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- Image resize\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\nheight, width = img.shape[:2]\n\ndst1 = cv2.resize(img, None, None, 0.5, 0.5, cv2.INTER_CUBIC)\ndst2 = cv2.resize(img, None, None, 2, 2, cv2.INTER_CUBIC)\n\nimg_rgb_dst1 = cv2.cvtColor(dst1, cv2.COLOR_BGR2RGB)\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_rgb_dst2 = cv2.cvtColor(dst2, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(5, 5))\nplt.imshow(img_rgb_dst1)\nplt.title('0.5x scaled')\nplt.axis('off')\nplt.show()\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img_rgb)\nplt.title('Original')\nplt.axis('off')\nplt.show()\n\nplt.figure(figsize=(20, 20))\nplt.imshow(img_rgb_dst2)\nplt.title('2x scaled')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- Image blurring\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\nblur1 = cv2.blur(img, (10,10))\n\nimg_rgb = cv2.cvtColor(blur1, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- Edge detection(밝기가 급격히 변하는 부분 감지)\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\nedges = cv2.Canny(img, 100, 200)\n\nimg_rgb = cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- Corner detection\n\nimg = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\ncorner = cv2.cornerHarris(gray, 2, 3, 0.04)\ncoord = np.where(corner &gt; 0.1*corner.max())\ncoord = np.stack((coord[1], coord[0]), axis=-1)\n\nfor x,y in coord:\n  cv2.circle(img, (x,y), 5, (0,0,255), 1, cv2.LINE_AA)\n\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb)\n\n\n\n\n\n\n\n\n- Image matching\n\nimg1 = cv2.imread('./example.jpg', cv2.IMREAD_UNCHANGED)\nimg2 = cv2.imread('./example4.jpg', cv2.IMREAD_UNCHANGED)\n\ngray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\ngray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n\ndetector = cv2.ORB_create()\nkp1, desc1 = detector.detectAndCompute(gray1, None)\nkp2, desc2 = detector.detectAndCompute(gray2, None)\n\nmatcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck = True)\nmatches = matcher.match(desc1, desc2)\n\nres = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, flags = cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n\nimg_rgb = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\nplt.imshow(img_rgb)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CV",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 23, 2026\n\n\n3. Review on PyTorch\n\n\n이상민 \n\n\n\n\nJan 21, 2026\n\n\n2. Review on Deep Learning\n\n\n이상민 \n\n\n\n\nJan 20, 2026\n\n\n1. Overview and Open CV\n\n\n이상민 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/03.Review_on_PyTorch.html",
    "href": "posts/03.Review_on_PyTorch.html",
    "title": "3. Review on PyTorch",
    "section": "",
    "text": "import torch\n\nw_true = torch.Tensor([1, 2, 3])\nb_true = 5\n\nw = torch.randn(3, requires_grad = True)\nb = torch.randn(1, requires_grad = True)\n\nX = torch.randn(100, 3)\ny = torch.mv(X, w_true) + b_true\n\ngamma = 0.1\nlosses = []\n\nfor i in range(100):\n    w.grad = None\n    b.grad = None\n\n    y_pred = torch.mv(X, w) + b\n    loss = torch.mean((y- y_pred)**2)\n    loss.backward()\n    \n    w.data = w.data - gamma * w.grad.data\n    b.data = b.data - gamma * b.grad.data\n    \n    losses.append(loss.item())\n\n\nprint('obtained w: ', w, 'true w:', w_true)\nprint('obtained b: ', b, 'true b:', b_true)\n\nobtained w:  tensor([1.0000, 2.0000, 3.0000], requires_grad=True) true w: tensor([1., 2., 3.])\nobtained b:  tensor([5.0000], requires_grad=True) true b: 5\n\n\n\nfrom matplotlib import pyplot as plt\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\n\n\n\nimport torch\n\nw_true = torch.Tensor([1, 2, 3])\nb_true = 5\n\nnet = torch.nn.Linear(in_features = 3, out_features = 1, bias = True)\n\nX = torch.randn(100, 3)\ny = torch.mv(X, w_true) + b_true\ngamma = 0.1\nlosses = []\n\noptimizer = torch.optim.SGD(net.parameters(), lr=gamma)\nloss_fn = torch.nn.MSELoss()\n\nfor i in range(100):\n    optimizer.zero_grad()\n    \n    y_pred = net(X)\n    \n    loss = loss_fn(y_pred.squeeze(1),y)\n    loss.backward()\n    \n    optimizer.step()\n    \n    losses.append(loss.item())\n\n\nprint(list(net.parameters()))\nfrom matplotlib import pyplot as plt\nplt.plot(losses)\n\n[Parameter containing:\ntensor([[1.0000, 2.0000, 3.0000]], requires_grad=True), Parameter containing:\ntensor([5.0000], requires_grad=True)]"
  },
  {
    "objectID": "posts/03.Review_on_PyTorch.html#linear-regresssion",
    "href": "posts/03.Review_on_PyTorch.html#linear-regresssion",
    "title": "3. Review on PyTorch",
    "section": "",
    "text": "import torch\n\nw_true = torch.Tensor([1, 2, 3])\nb_true = 5\n\nw = torch.randn(3, requires_grad = True)\nb = torch.randn(1, requires_grad = True)\n\nX = torch.randn(100, 3)\ny = torch.mv(X, w_true) + b_true\n\ngamma = 0.1\nlosses = []\n\nfor i in range(100):\n    w.grad = None\n    b.grad = None\n\n    y_pred = torch.mv(X, w) + b\n    loss = torch.mean((y- y_pred)**2)\n    loss.backward()\n    \n    w.data = w.data - gamma * w.grad.data\n    b.data = b.data - gamma * b.grad.data\n    \n    losses.append(loss.item())\n\n\nprint('obtained w: ', w, 'true w:', w_true)\nprint('obtained b: ', b, 'true b:', b_true)\n\nobtained w:  tensor([1.0000, 2.0000, 3.0000], requires_grad=True) true w: tensor([1., 2., 3.])\nobtained b:  tensor([5.0000], requires_grad=True) true b: 5\n\n\n\nfrom matplotlib import pyplot as plt\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\n\n\n\nimport torch\n\nw_true = torch.Tensor([1, 2, 3])\nb_true = 5\n\nnet = torch.nn.Linear(in_features = 3, out_features = 1, bias = True)\n\nX = torch.randn(100, 3)\ny = torch.mv(X, w_true) + b_true\ngamma = 0.1\nlosses = []\n\noptimizer = torch.optim.SGD(net.parameters(), lr=gamma)\nloss_fn = torch.nn.MSELoss()\n\nfor i in range(100):\n    optimizer.zero_grad()\n    \n    y_pred = net(X)\n    \n    loss = loss_fn(y_pred.squeeze(1),y)\n    loss.backward()\n    \n    optimizer.step()\n    \n    losses.append(loss.item())\n\n\nprint(list(net.parameters()))\nfrom matplotlib import pyplot as plt\nplt.plot(losses)\n\n[Parameter containing:\ntensor([[1.0000, 2.0000, 3.0000]], requires_grad=True), Parameter containing:\ntensor([5.0000], requires_grad=True)]"
  },
  {
    "objectID": "posts/03.Review_on_PyTorch.html#multi-layer-perceptron",
    "href": "posts/03.Review_on_PyTorch.html#multi-layer-perceptron",
    "title": "3. Review on PyTorch",
    "section": "2. Multi-layer perceptron",
    "text": "2. Multi-layer perceptron\n\n\\(y = \\sigma(w_3(\\sigma(w_2(\\sigma(w_1x+b_1))+b_2))+ b_3)\\)\n\\(\\sigma\\) : Sigmoid, Tanh, ReLu and so on..\n\n\n1) Implementing Multi-layer perceptron using PyTorch\n\nimport torch\n\nnum_data = 1000\nnum_epoch = 10000\nx = torch.randn(num_data, 1)\ny = (x**2) + 3\n\nnet = torch.nn.Sequential(\ntorch.nn.Linear(1,6),\ntorch.nn.ReLU(),\ntorch.nn.Linear(6, 10),\ntorch.nn.ReLU(),\ntorch.nn.Linear(10, 6),\ntorch.nn.ReLU(),\ntorch.nn.Linear(6, 1),\n)\n\nloss_func = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\nlosses = []\n\nfor i in range(num_epoch):\n    optimizer.zero_grad()\n    \n    output = net(x)\n    \n    loss = loss_func(output, y)\n    loss.backward()\n    \n    optimizer.step()\n    \n    losses.append(loss.item())\n\n\nfrom matplotlib import pyplot as plt\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\nx = torch.randn(5, 1)\ny = (x**2) + 3\ny_pred = net(x)\nprint(y)\nprint(y_pred)\n\ntensor([[3.1069],\n        [3.6161],\n        [3.0239],\n        [3.0206],\n        [3.0046]])\ntensor([[3.1685],\n        [3.6404],\n        [3.0821],\n        [2.9325],\n        [3.0386]], grad_fn=&lt;AddmmBackward0&gt;)"
  },
  {
    "objectID": "posts/03.Review_on_PyTorch.html#cnn",
    "href": "posts/03.Review_on_PyTorch.html#cnn",
    "title": "3. Review on PyTorch",
    "section": "3. CNN",
    "text": "3. CNN\n\n1) CNN implementation in PyTorch\n\nimport torch\nimport torch.nn\n\nclass MyCNN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer = torch.nn.Sequential(\n            torch.nn.Conv2d(1, 16, 5),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(16, 32, 5),\n            torch.nn.MaxPool2d(2, 2),\n            torch.nn.Conv2d(32, 64, 5),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(2,2)\n        )\n        self.fc_layer = torch.nn.Sequential(\n            torch.nn.Linear(64*52*52, 100),\n            torch.nn.ReLU(),\n            torch.nn.Linear(100, 10)\n        )\n\n    def forward(self, x):\n        out = self.layer(x)\n        out = out.view(out.size(0), -1)\n        out = self.fc_layer(out)\n        return out\n\n\nimport numpy as np\nnum_data = 1000\nnum_epoch = 10\nx = torch.randn(num_data,1, 224,224)\ny = torch.tensor(np.random.choice([0,1], 1000), dtype = torch.long)\n\n\nnet = MyCNN()\n\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n\nlosses = []\n\nfor i in range(num_epoch):\n    optimizer.zero_grad()\n    \n    output = net(x)\n    \n    loss = loss_func(output, y)\n    loss.backward()\n    \n    optimizer.step()\n\n    losses.append(loss.item())\n\n\n## Cross entropy loss\nimport torch.nn as nn\n\nloss = nn.CrossEntropyLoss()\n\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.empty(3, dtype=torch.long).random_(5)\n\noutput = loss(input, target)\n\nprint(input)\nprint(target)\nprint(output)\n\ntensor([[-1.6207,  0.8775,  1.0726,  0.0215,  2.0341],\n        [-0.2897,  1.6222,  0.3694,  2.3245, -0.9064],\n        [-0.2044, -2.1951, -2.7583, -0.3929,  1.6202]], requires_grad=True)\ntensor([3, 3, 3])\ntensor(1.8295, grad_fn=&lt;NllLossBackward0&gt;)\n\n\n\n\n2)Stochastic Gradient Descent\n\nGradient descent\n\nCalculate for all data\nGo 1 optimal step\n\nStochastic gradient descent\n\nCalcultate gradients for partial data\nGo many non-globally-optimal steps, but converges\n\n\n\n\n\n3) LeNet\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\nimport matplotlib.pyplot as plt\n\nLEARNING_RATE = 0.001\nBATCH_SIZE = 32\nN_EPOCHS = 10\n\nIMG_SIZE = 32\nN_CLASSES = 10\n\n\nclass LeNet5(nn.Module):\n    def __init__(self, n_classes):\n        super(LeNet5, self).__init__()\n        \n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n            nn.Tanh(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n            nn.Tanh(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n            nn.Tanh()\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(in_features=120, out_features=84),\n            nn.Tanh(),\n            nn.Linear(in_features=84, out_features=n_classes),\n        )\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n\ntrans = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\ntrain_dataset = datasets.MNIST(root = 'mnist_data', train=True, transform=trans, download=True)\ntest_dataset = datasets.MNIST(root = 'mnist_data', train=False, transform=trans)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:02&lt;00:00, 3449235.73it/s]\n\n\nExtracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n\n\n100%|█████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00&lt;00:00, 156533.97it/s]\n\n\nExtracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n\n\n100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01&lt;00:00, 1194631.91it/s]\n\n\nExtracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\n\n100%|██████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00&lt;00:00, 6453431.15it/s]\n\n\nExtracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n\n\n\n\n\n\n\nA) GPU이용 x\n\ndef train(train_loader, model, criterion, optimizer):\n    model.train()\n    train_loss = 0\n    correct = 0\n    for X, y_true in train_loader:\n        optimizer.zero_grad()\n        \n        y_hat = model(X)\n        loss = criterion(y_hat, y_true)\n        \n        train_loss += loss.item()\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        correct += pred.eq(y_true.view_as(pred)).sum().item()\n        \n        loss.backward()\n        optimizer.step()\n    \n    epoch_loss = train_loss / len(train_loader.dataset)\n    acc = correct / len(train_loader.dataset)\n    \n    return model, optimizer, epoch_loss, acc\n\n\ndef test(test_loader, model, criterion):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    \n    for X, y_true in test_loader:\n        \n        y_hat = model(X)\n        loss = criterion(y_hat, y_true)\n        \n        test_loss += loss.item()\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        correct += pred.eq(y_true.view_as(pred)).sum().item()\n        \n    epoch_loss = test_loss / len(test_loader.dataset)\n    acc = correct / len(test_loader.dataset)\n\n    \n    return model, epoch_loss, acc\n\n\ndef training_loop(model, criterion, optimizer, train_loader, test_loader, epochs, print_every=1):\n    train_losses = []\n    test_losses = []\n    for epoch in range(epochs):\n        model, optimizer, train_loss, train_acc = train(train_loader, model, criterion, optimizer)\n        train_losses.append(train_loss)\n        with torch.no_grad():\n            model, test_loss, test_acc = test(test_loader, model, criterion)\n            test_losses.append(test_loss)\n        if epoch % print_every == (print_every - 1):\n            print(f'Epoch: {epoch}\\t'\n                f'Train loss: {train_loss:.4f}\\t'\n                f'Test loss: {test_loss:.4f}\\t'\n                f'Train accuracy: {100 * train_acc:.2f}\\t'\n                f'Test accuracy: {100 * test_acc:.2f}')\n    return model, optimizer, (train_losses, test_losses)\n\n\nmodel = LeNet5(N_CLASSES)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.CrossEntropyLoss()\n\nmodel, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, test_loader, N_EPOCHS)\n\nEpoch: 0    Train loss: 0.0718  Test loss: 0.0717   Train accuracy: 11.12   Test accuracy: 11.44\nEpoch: 1    Train loss: 0.0712  Test loss: 0.0707   Train accuracy: 15.21   Test accuracy: 31.99\nEpoch: 2    Train loss: 0.0689  Test loss: 0.0660   Train accuracy: 49.09   Test accuracy: 62.09\nEpoch: 3    Train loss: 0.0583  Test loss: 0.0482   Train accuracy: 61.26   Test accuracy: 64.36\nEpoch: 4    Train loss: 0.0396  Test loss: 0.0317   Train accuracy: 67.64   Test accuracy: 73.92\nEpoch: 5    Train loss: 0.0275  Test loss: 0.0235   Train accuracy: 77.19   Test accuracy: 81.42\nEpoch: 6    Train loss: 0.0216  Test loss: 0.0192   Train accuracy: 82.31   Test accuracy: 84.22\nEpoch: 7    Train loss: 0.0183  Test loss: 0.0166   Train accuracy: 84.57   Test accuracy: 86.17\nEpoch: 8    Train loss: 0.0162  Test loss: 0.0149   Train accuracy: 86.02   Test accuracy: 87.38\nEpoch: 9    Train loss: 0.0147  Test loss: 0.0136   Train accuracy: 87.18   Test accuracy: 88.43\n\n\n\n\nB) GPU 이용\n\ndef train(train_loader, model, criterion, optimizer, device):\n    model.train()\n    train_loss = 0\n    correct = 0\n    for X, y_true in train_loader:\n        optimizer.zero_grad()\n\n        X = X.to(device)\n        y_true = y_true.to(device)\n\n        y_hat = model(X)\n        loss = criterion(y_hat, y_true)\n        \n        train_loss += loss.item()\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        correct += pred.eq(y_true.view_as(pred)).sum().item()\n        \n        loss.backward()\n        optimizer.step()\n    \n    epoch_loss = train_loss / len(train_loader.dataset)\n    acc = correct / len(train_loader.dataset)\n    \n    return model, optimizer, epoch_loss, acc\n\n\ndef test(test_loader, model, criterion, device):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    \n    for X, y_true in test_loader:\n        \n        X = X.to(device)\n        y_true = y_true.to(device)\n        \n        y_hat = model(X)\n        loss = criterion(y_hat, y_true)\n        \n        test_loss += loss.item()\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        correct += pred.eq(y_true.view_as(pred)).sum().item()\n        \n    epoch_loss = test_loss / len(test_loader.dataset)\n    acc = correct / len(test_loader.dataset)\n\n    \n    return model, epoch_loss, acc\n\n\ndef training_loop(model, criterion, optimizer, train_loader, test_loader, epochs, device, print_every=1):\n    train_losses = []\n    test_losses = []\n    for epoch in range(epochs):\n        model, optimizer, train_loss, train_acc = train(train_loader, model, criterion, optimizer, device)\n        train_losses.append(train_loss)\n        with torch.no_grad():\n            model, test_loss, test_acc = test(test_loader, model, criterion, device)\n            test_losses.append(test_loss)\n        if epoch % print_every == (print_every - 1):\n            print(f'Epoch: {epoch}\\t'\n                f'Train loss: {train_loss:.4f}\\t'\n                f'Test loss: {test_loss:.4f}\\t'\n                f'Train accuracy: {100 * train_acc:.2f}\\t'\n                f'Test accuracy: {100 * test_acc:.2f}')\n    return model, optimizer, (train_losses, test_losses)\n\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDEVICE\n\n'cuda'\n\n\n\nmodel = LeNet5(N_CLASSES).to(DEVICE)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.CrossEntropyLoss()\n\nmodel, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, test_loader, N_EPOCHS, DEVICE)\n\nEpoch: 0    Train loss: 0.0717  Test loss: 0.0715   Train accuracy: 12.12   Test accuracy: 24.27\nEpoch: 1    Train loss: 0.0707  Test loss: 0.0696   Train accuracy: 35.98   Test accuracy: 40.96\nEpoch: 2    Train loss: 0.0659  Test loss: 0.0596   Train accuracy: 46.88   Test accuracy: 53.71\nEpoch: 3    Train loss: 0.0504  Test loss: 0.0404   Train accuracy: 60.58   Test accuracy: 69.89\nEpoch: 4    Train loss: 0.0336  Test loss: 0.0276   Train accuracy: 74.09   Test accuracy: 79.12\nEpoch: 5    Train loss: 0.0245  Test loss: 0.0213   Train accuracy: 81.22   Test accuracy: 83.96\nEpoch: 6    Train loss: 0.0199  Test loss: 0.0178   Train accuracy: 84.45   Test accuracy: 86.18\nEpoch: 7    Train loss: 0.0171  Test loss: 0.0156   Train accuracy: 86.00   Test accuracy: 87.37\nEpoch: 8    Train loss: 0.0153  Test loss: 0.0141   Train accuracy: 87.15   Test accuracy: 88.03\nEpoch: 9    Train loss: 0.0140  Test loss: 0.0130   Train accuracy: 87.95   Test accuracy: 88.87\n\n\n\n\n\n4) ResNet\n\nUse network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping\n\n\n\ndef conv_block_1(in_dim,out_dim,act_fn):\n    model = nn.Sequential(\n        nn.Conv2d(in_dim,out_dim, kernel_size=1, stride=1),\n        act_fn,\n    )\n    return model\n    \ndef conv_block_1_stride_2(in_dim,out_dim,act_fn):\n    model = nn.Sequential(\n        nn.Conv2d(in_dim,out_dim, kernel_size=1, stride=2),\n        act_fn,\n    )\n    return model\n    \ndef conv_block_1_n(in_dim,out_dim):\n    model = nn.Sequential(\n        nn.Conv2d(in_dim,out_dim, kernel_size=1, stride=1),\n    )\n    return model\n\ndef conv_block_1_stride_2_n(in_dim,out_dim):\n    model = nn.Sequential(\n        nn.Conv2d(in_dim,out_dim, kernel_size=1, stride=2),\n    )\n    return model\n\ndef conv_block_3(in_dim,out_dim,act_fn):\n    model = nn.Sequential(\n        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n        act_fn,\n    )\n    return model\n\n\nclass BottleNeck(nn.Module):\n    def __init__(self,in_dim,mid_dim,out_dim,act_fn):\n        super(BottleNeck,self).__init__()\n        self.layer = nn.Sequential(\n            conv_block_1(in_dim,mid_dim,act_fn),\n            conv_block_3(mid_dim,mid_dim,act_fn),\n            conv_block_1_n(mid_dim,out_dim),\n        )\n        self.downsample = nn.Conv2d(in_dim,out_dim,1,1)\n        \n    def forward(self,x):\n        downsample = self.downsample(x)\n        out = self.layer(x)\n        out = out + downsample\n        \n        return out\n    \nclass BottleNeck_no_down(nn.Module):\n    def __init__(self,in_dim,mid_dim,out_dim,act_fn):\n        super(BottleNeck_no_down,self).__init__()\n        self.layer = nn.Sequential(\n            conv_block_1(in_dim,mid_dim,act_fn),\n            conv_block_3(mid_dim,mid_dim,act_fn),\n            conv_block_1_n(mid_dim,out_dim),\n        )\n    def forward(self,x):\n        out = self.layer(x)\n        out = out + x\n        \n        return out\n\n\nclass BottleNeck_stride(nn.Module):\n    def __init__(self,in_dim,mid_dim,out_dim,act_fn):\n        \n        super(BottleNeck_stride,self).__init__()\n        self.layer = nn.Sequential(\n            conv_block_1_stride_2(in_dim,mid_dim,act_fn),\n            conv_block_3(mid_dim,mid_dim,act_fn),\n            conv_block_1_n(mid_dim,out_dim),\n        )\n        self.downsample = nn.Conv2d(in_dim,out_dim,1,2)\n    def forward(self,x):\n        \n        downsample = self.downsample(x)\n        out = self.layer(x)\n        out = out + downsample\n        \n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, base_dim, num_classes=2):\n        super(ResNet, self).__init__()\n        self.act_fn = nn.ReLU()\n        \n        self.layer_1 = nn.Sequential(\n            nn.Conv2d(3,base_dim,7,2,3),\n            nn.ReLU(),\n            nn.MaxPool2d(3,2,1),\n        )\n        \n        self.layer_2 = nn.Sequential(\n            BottleNeck(base_dim,base_dim,base_dim*4,self.act_fn),\n            BottleNeck_no_down(base_dim*4,base_dim,base_dim*4,self.act_fn),\n            BottleNeck_stride(base_dim*4,base_dim,base_dim*4,self.act_fn),\n        )\n        self.layer_3 = nn.Sequential(\n            BottleNeck(base_dim*4,base_dim*2,base_dim*8,self.act_fn),\n            BottleNeck_no_down(base_dim*8,base_dim*2,base_dim*8,self.act_fn),\n            BottleNeck_no_down(base_dim*8,base_dim*2,base_dim*8,self.act_fn),\n            BottleNeck_stride(base_dim*8,base_dim*2,base_dim*8,self.act_fn),\n        )\n        self.layer_4 = nn.Sequential(\n            BottleNeck(base_dim*8,base_dim*4,base_dim*16,self.act_fn),\n            BottleNeck_no_down(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n            BottleNeck_no_down(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n            BottleNeck_no_down(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n            BottleNeck_no_down(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n            BottleNeck_stride(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n        )\n        self.layer_5 = nn.Sequential(\n            BottleNeck(base_dim*16,base_dim*8,base_dim*32,nn.ReLU()),\n            BottleNeck_no_down(base_dim*32,base_dim*8,base_dim*32,self.act_fn),\n            BottleNeck(base_dim*32,base_dim*8,base_dim*32,self.act_fn),\n        )\n        self.avgpool = nn.AvgPool2d(7,1)\n        self.fc_layer = nn.Linear(base_dim*32,num_classes)\n    \n    def forward(self, x):\n        out = self.layer_1(x)\n        out = self.layer_2(out)\n        out = self.layer_3(out)\n        out = self.layer_4(out)\n        out = self.layer_5(out)\n        out = self.avgpool(out)\n        out = out.view(batch_size,-1)\n        out = self.fc_layer(out)\n        \n        return out"
  }
]